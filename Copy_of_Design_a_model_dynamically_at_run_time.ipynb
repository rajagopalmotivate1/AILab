{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Design a model dynamically at run time",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajagopalmotivate1/AILab/blob/master/Copy_of_Design_a_model_dynamically_at_run_time.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dZufBgI-XafV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "FcPI2LGHnml2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Network architecture search"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SIIaEnJKnm7Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#My First step towards Neural Architecture Search\n",
        "## 3 child neural networks are created dynamically on the fly"
      ]
    },
    {
      "metadata": {
        "id": "Yfg6g-BiqNa9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Tip: First, Run with epochs=1 to ensure all child networks can run smoothly, Then change to  epochs=10 to improve accuracy of classification"
      ]
    },
    {
      "metadata": {
        "id": "--lqqqFOhnKa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install pydot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5lTttxUFPETn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "K.tensorflow_backend._get_available_gpus()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zH6wDYAeXYZR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import Input\n",
        "from keras import layers\n",
        "from keras import datasets\n",
        "import numpy as np\n",
        "from keras import utils\n",
        "from keras.models import  Model\n",
        "from keras.utils import plot_model\n",
        "import keras\n",
        "import os\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "from decimal import Decimal\n",
        "import  matplotlib.pyplot as plt\n",
        "from scipy.misc import toimage\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bhLMomrdMtQH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "from google.colab import files\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KNZ-mJHFgMar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Input parameters are depthofnetwork, generalization capacity , \n",
        "\n",
        "def createANetwork(ExpNo, noofCNNlayers, noofDenselayers, noofCNNFilters, noofDensenodes  ,\n",
        "                  networkwidthTamperRate, stride, maxpool, noofPARALLELbranches , kernalsize):\n",
        "    myinputShape = (32, 32, 3)\n",
        "    myinputTensor = Input(shape=myinputShape, name='1')\n",
        "    x = myinputTensor\n",
        "    layerno = 1\n",
        "    isskipaddingMaxPool = True\n",
        "    \n",
        "    for i in range(noofCNNlayers):\n",
        "        x = layers.Conv2D(noofCNNFilters, kernel_size=(kernalsize,kernalsize), strides=(stride,stride), activation='relu', name='CNNlayer'+str(layerno)) (x)\n",
        "        print( str(layerno) + ' Conv2D  Filters=' + str(noofCNNFilters) + '.    kernel size=(' + str(kernalsize) + ' , ' + str(kernalsize) + ' )'  + ' . stride=' + str(stride) + '     Relu')\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        layerno = layerno +1\n",
        "        if(layerno > 3):\n",
        "            maxpool = 1\n",
        "        if(layerno > 1):\n",
        "            stride = 1\n",
        "        if (isskipaddingMaxPool == False):\n",
        "            x = layers.MaxPooling2D(pool_size=(maxpool, maxpool), name='MaxPool'+str(layerno)) (x)\n",
        "            print( str(layerno) + ' MaxPool  . Poolsize=' + str(maxpool) )\n",
        "            layerno = layerno +1\n",
        "            x = layers.Dropout(0.2) (x)\n",
        "            print( '  Dropout 0.2' )\n",
        "            isskipaddingMaxPool = True\n",
        "            noofCNNFilters = round( noofCNNFilters * networkwidthTamperRate )\n",
        "            if(noofCNNFilters>512):\n",
        "                noofCNNFilters = 512\n",
        "        else:\n",
        "            isskipaddingMaxPool = False\n",
        "\n",
        "\n",
        "    x = layers.Flatten(name='Flatten' + str(layerno) ) (x)\n",
        "    print(str(layerno) + ' Flatten  ' )\n",
        "\n",
        "    layerno = layerno + 1\n",
        "\n",
        "    for i in range(noofDenselayers):\n",
        "        x = layers.Dense(noofDensenodes, activation='relu', name='Dense'+ str(layerno) )(x)\n",
        "        print( str(layerno) + ' Dense  ' + str(noofDensenodes) )\n",
        "        layerno = layerno +1\n",
        "        noofDensenodes = round(noofDensenodes/2)\n",
        "\n",
        "    myoutputTensor = layers.Dense(10, activation='softmax', name='DenseMultiClassSoftmaxLayer') (x)\n",
        "\n",
        "    mymodel = Model(myinputTensor, myoutputTensor)\n",
        "\n",
        "    \n",
        "    plot_model(mymodel, show_shapes=False, show_layer_names=True, to_file='achildmodel.png')\n",
        "    print(mymodel.summary())\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "  #  plot_model(mymodel, show_shapes=True, to_file='models'+str(ExpNo) + '.png')\n",
        "   # plot_model(mymodel, show_shapes=False, to_file='m'+str(ExpNo) + '.png')\n",
        "\n",
        "\n",
        "    return mymodel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XJX4hB8BgOj9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_callbacks(expno):\n",
        "   # tensorboard_callback = TensorBoard(log_dir=os.path.join(os.getcwd(), \"log\", \"am18d301_Exp1\" + str(expno) ), histogram_freq=1, batch_size=32,   write_graph=False, write_grads=False)\n",
        "   # checkpoint_callback = ModelCheckpoint(filepath=\"./model-weights.{epoch:02d}.hdf5\", monitor='val_acc', verbose=0, save_best_only=True)\n",
        "    earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=1, verbose=1, mode='auto')\n",
        "    return [ earlystop]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DgMRQjrTgRKR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_model_metrics(model, xtest, ytest ):\n",
        "    loss, accuracy = model.evaluate(x=xtest, y=ytest)\n",
        "    print(\"\\n model test loss is \"+str(loss)+\" accuracy is \"+str(accuracy))\n",
        "\n",
        "    y_softmax = model.predict(xtest)  # this is an n x class matrix of probabilities\n",
        "    y_hat = y_softmax.argmax(axis=-1)  # this will be the class number.\n",
        "    test_y = ytest.argmax(axis=-1)  # our test data is also categorical\n",
        "    print(classification_report(test_y, y_hat))\n",
        "    return [loss, accuracy]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-QnaNl67gTnx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_imgs(X):\n",
        "    plt.figure(1)\n",
        "    k = 0\n",
        "    for i in range(0,4):\n",
        "        for j in range(0,4):\n",
        "            plt.subplot2grid((4,4),(i,j))\n",
        "            plt.imshow(toimage(X[k]))\n",
        "            k = k+1\n",
        "    # show the plot\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VtGT5APagV5D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convertprecision(alongfloat):\n",
        "    alongfloat1 = Decimal(alongfloat * 100)\n",
        "    alongfloat2 = round(alongfloat1, 2)\n",
        "    myformatedfloat = float(alongfloat2)\n",
        "    return myformatedfloat "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wE18NNodgj6M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def runaexpeirment(ExpName, anetworkmodel):\n",
        "\n",
        "    mymodel = anetworkmodel\n",
        "\n",
        "    (xtrain1, ytrain1), (xtest, ytest) = datasets.cifar10.load_data()\n",
        "    \n",
        "    plot_imgs(xtrain1[:16])\n",
        "\n",
        "    xtrain  = xtrain1[:42000, :]\n",
        "    ytrain = ytrain1[:42000, :]\n",
        "\n",
        "    xval = xtrain1[42000:, :]\n",
        "    yval = ytrain1[42000:, :]\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "    datagen.fit(xtrain)\n",
        "    \n",
        "\n",
        "    print( 'Shape of CIFAR Training Set Inputs: ' + str(xtrain.shape) )\n",
        "    print( 'Shape of CIFAR Training Set Labels: ' + str(ytrain.shape) )\n",
        "    print( 'Shape of CIFAR Test Set Inputs: ' + str(xtest.shape) )\n",
        "    print( 'Shape of CIFAR Validation Set Inputs: ' + str(xval.shape) )\n",
        "\n",
        "\n",
        "    xtrain = xtrain.astype('float16') * 1/255\n",
        "    xtest = xtest.astype('float16') * 1/255\n",
        "    xval = xval.astype('float16') * 1/255\n",
        "\n",
        "    trainSetSize = len(xtrain)\n",
        "    testSetSize = len(xtest)\n",
        "    valSetSize = len(xval)\n",
        "\n",
        "    xtrain = xtrain.reshape((trainSetSize, 32, 32, 3))\n",
        "    xtest = xtest.reshape((testSetSize, 32, 32, 3))\n",
        "    xval = xval.reshape((valSetSize,32, 32, 3))\n",
        "\n",
        "    ytrain = utils.to_categorical(ytrain)\n",
        "    ytest = utils.to_categorical(ytest)\n",
        "    yval = utils.to_categorical(yval)\n",
        "\n",
        "    print('After preprocessing.. normalize to 1, OHE, reshaping')\n",
        "    print( 'Shape of CIFAR Training Set Inputs: ' + str(xtrain.shape) )\n",
        "    print( 'Shape of CIFAR Training Set Labels: ' + str(ytrain.shape) )\n",
        "    print( 'Shape of CIFAR Test Set Inputs: ' + str(xtest.shape) )\n",
        "\n",
        "\n",
        "    mymodel.compile(optimizer=keras.optimizers.RMSprop(), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "    mycallbacksfunction = create_callbacks(ExpName)\n",
        "\n",
        "   # history = mymodel.fit(xtrain, ytrain, epochs=2, batch_size=128,\n",
        "                         # validation_data=(xval,yval),\n",
        "                         # verbose=1, \n",
        "                         # callbacks=mycallbacksfunction\n",
        "                         # )\n",
        "\n",
        "    mybatchsize = 128\n",
        "    history = mymodel.fit_generator( datagen.flow(xtrain, ytrain, batch_size=mybatchsize),\n",
        "                    steps_per_epoch=xtrain.shape[0] / mybatchsize, \n",
        "                    epochs=1,\n",
        "                    verbose=1,\n",
        "                    validation_data=(xval,yval)\n",
        "                      )\n",
        "\n",
        "    #save to disk\n",
        "    model_json = mymodel.to_json()\n",
        "    with open('model' + str(ExpName) + 's.json', 'w') as json_file:\n",
        "        json_file.write(model_json)\n",
        "    mymodel.save_weights('model'  + str(ExpName) + 's.h5') \n",
        "\n",
        "    myTESTloss, myTESTaccuracy = print_model_metrics( mymodel, xtest, ytest )\n",
        "    myVALloss, myVALaccuracy = print_model_metrics( mymodel, xval, yval )\n",
        "    myTRAINloss, myTRAINaccuracy = print_model_metrics( mymodel, xtrain, ytrain)\n",
        "\n",
        "    myTESTaccuracy = convertprecision(myTESTaccuracy)\n",
        "    myVALaccuracy = convertprecision(myVALaccuracy)\n",
        "    myTRAINaccuracy = convertprecision(myTRAINaccuracy)\n",
        "    \n",
        "\n",
        "    print(' \\n RESULTS')\n",
        "    print('TRAINING accuracy = ' + str(myTRAINaccuracy ))\n",
        "    print('VAL accuracy = ' + str(myVALaccuracy))\n",
        "    print('TEST accuracy = ' + str(myTESTaccuracy))\n",
        "    \n",
        "    \n",
        "\n",
        "    return myTRAINaccuracy, myVALaccuracy, myTESTaccuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rC0hKiLpgq7V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Find insights about a network such as how deep is the network, memorizationcapacity, generalizationcapacity, noofCNNs, kernalsize, amountofnonlinearity\n",
        "def extractNetworkInsights(anetwork):\n",
        "    print('Analzing the Network insights')\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XdmvepWLraYo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### createANetwork() creates a network. Change these values with care. \n",
        "#### NOTE: Some values may not yeild a valid model, hence alter with care. And then try with epoch=1 to ensure the model can be trained, else an exception may occur\n",
        "#### createANetwork(ExpNo, noofCNNlayers, noofDenselayers, noofCNNFilters, noofDensenodes  , noofPARALLELbranches , networkwidthTamperRate)\n",
        "#####ExpNo- just the experiement serial number.. simply to count how many childs are created\n",
        "#####noofCNNlayers - no of CNN layers that should be created \n",
        "#####noofDenselayers - no of Dense layers that should be created which will usually towards the end of the network\n",
        "#####noofDensenodes - no of nodes in the Dense layer \n",
        "#####noofPARALLELbranches - NOT yet implemented. Future is to use Inception style model with 3 to 4 parallel paths \n",
        "#####noofCNNFilters - no of filters in the CNN layers\n",
        "#####networkwidthTamperRate -  Controls the size of each subsequent layer.  If this is 2, the no of filters in each subsequent CNN layer will be doubled. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "hCnaRjjrgxBK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ExpName = 2000\n",
        "islistcreated = False\n",
        "ListofNetworks = list()\n",
        "nooffiltersstarting =  32\n",
        "networkwidthTamperRate = 2\n",
        "noofDenselayers = 0\n",
        "noofDensenodes = 64 \n",
        "stride = 1\n",
        "maxpool = 2\n",
        "noofPARALLELbranches = 1\n",
        "noofCNNlayers = 6\n",
        "kernalsize = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8PRTohI2rYpH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KrVQaDstg1V5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#def createANetwork(ExpNo, noofCNNlayers, noofDenselayers, noofCNNFilters, noofDensenodes  , noofPARALLELbranches , networkwidthTamperRate):\n",
        "\n",
        "for iterate in range( 0, 1):\n",
        "  \n",
        "    ExpName = ExpName + 1\n",
        "    generatedNetwork =  createANetwork(ExpName, noofCNNlayers,noofDenselayers, nooffiltersstarting, noofDensenodes  ,networkwidthTamperRate, stride, maxpool,  noofPARALLELbranches, kernalsize )\n",
        "\n",
        "    aTRAINaccuracy, aVALaccuracy, aTESTaccuracy = runaexpeirment(ExpName, generatedNetwork )\n",
        "\n",
        "    atuple = tuple((ExpName, aTRAINaccuracy, aVALaccuracy, aTESTaccuracy ,  noofCNNlayers,noofDenselayers,  nooffiltersstarting, noofDensenodes  ,networkwidthTamperRate  , stride, maxpool, noofPARALLELbranches , kernalsize, generatedNetwork))\n",
        "\n",
        "    ListofNetworks.append(atuple)\n",
        "\n",
        "    print(\" ADDED\")\n",
        "    print(atuple)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2mUU-kAMrFT4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## This creates 3 models . \n",
        "### By changing the value of noofCNNlayers, each time we create a model with different number of layers. \n",
        "\n",
        "### In the below values, Initally we create with a CNN with 3 CNN layers, then with 4 CNN layers, then with 5 CNN layers"
      ]
    },
    {
      "metadata": {
        "id": "U9fCGeVWMHn9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#def createANetwork(ExpNo, noofCNNlayers, noofDenselayers, noofCNNFilters, noofDensenodes  , noofPARALLELbranches , networkwidthTamperRate):\n",
        "\n",
        "\n",
        "for iterate in range( 3, 6, 1):\n",
        "  \n",
        "    noofCNNlayers = iterate \n",
        "  \n",
        "    ExpName = ExpName + 1\n",
        "    generatedNetwork =  createANetwork(ExpName, noofCNNlayers,noofDenselayers, nooffiltersstarting, noofDensenodes  ,networkwidthTamperRate, stride, maxpool,  noofPARALLELbranches, kernalsize )\n",
        "    aTRAINaccuracy, aVALaccuracy, aTESTaccuracy = runaexpeirment(ExpName, generatedNetwork )\n",
        "\n",
        "    atuple = tuple((ExpName, aTRAINaccuracy, aVALaccuracy, aTESTaccuracy ,  noofCNNlayers,noofDenselayers,  nooffiltersstarting, noofDensenodes  ,networkwidthTamperRate  , stride, maxpool, noofPARALLELbranches , kernalsize, generatedNetwork))\n",
        "\n",
        "    ListofNetworks.append(atuple)\n",
        "\n",
        "    print(\" ADDED\")\n",
        "    print(atuple)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Tz0yrr5ljE0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(xtraincheck, ytraincheck), (xtestcheck, ytestcheck) = datasets.cifar10.load_data()\n",
        "myimageJ = xtraincheck[114]\n",
        "myimageJnormalized = myimageJ.astype('float16') * 1/255"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}