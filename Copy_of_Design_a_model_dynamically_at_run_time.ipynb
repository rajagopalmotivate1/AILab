{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Design a model dynamically at run time",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajagopalmotivate1/AILab/blob/master/Copy_of_Design_a_model_dynamically_at_run_time.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dZufBgI-XafV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "--lqqqFOhnKa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install pydot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5lTttxUFPETn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "K.tensorflow_backend._get_available_gpus()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zH6wDYAeXYZR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import Input\n",
        "from keras import layers\n",
        "from keras import datasets\n",
        "import numpy as np\n",
        "from keras import utils\n",
        "from keras.models import  Model\n",
        "from keras.utils import plot_model\n",
        "import keras\n",
        "import os\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "from decimal import Decimal\n",
        "import  matplotlib.pyplot as plt\n",
        "from scipy.misc import toimage\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bhLMomrdMtQH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "from google.colab import files\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KNZ-mJHFgMar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Input parameters are depthofnetwork, generalization capacity , \n",
        "\n",
        "def createANetwork(ExpNo, noofCNNlayers, noofDenselayers, noofCNNFilters, noofDensenodes  ,\n",
        "                  networkwidthTamperRate, stride, maxpool, noofPARALLELbranches , kernalsize):\n",
        "    myinputShape = (32, 32, 3)\n",
        "    myinputTensor = Input(shape=myinputShape, name='1')\n",
        "    x = myinputTensor\n",
        "    layerno = 1\n",
        "    isskipaddingMaxPool = True\n",
        "    \n",
        "    for i in range(noofCNNlayers):\n",
        "        x = layers.Conv2D(noofCNNFilters, kernel_size=(kernalsize,kernalsize), strides=(stride,stride), activation='relu', name='CNNlayer'+str(layerno)) (x)\n",
        "        print( str(layerno) + ' Conv2D  Filters=' + str(noofCNNFilters) + '.    kernel size=(' + str(kernalsize) + ' , ' + str(kernalsize) + ' )'  + ' . stride=' + str(stride) + '     Relu')\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        layerno = layerno +1\n",
        "        if(layerno > 3):\n",
        "            maxpool = 1\n",
        "        if(layerno > 1):\n",
        "            stride = 1\n",
        "        if (isskipaddingMaxPool == False):\n",
        "            x = layers.MaxPooling2D(pool_size=(maxpool, maxpool), name='MaxPool'+str(layerno)) (x)\n",
        "            print( str(layerno) + ' MaxPool  . Poolsize=' + str(maxpool) )\n",
        "            layerno = layerno +1\n",
        "            x = layers.Dropout(0.2) (x)\n",
        "            print( '  Dropout 0.2' )\n",
        "            isskipaddingMaxPool = True\n",
        "            noofCNNFilters = round( noofCNNFilters * networkwidthTamperRate )\n",
        "            if(noofCNNFilters>512):\n",
        "                noofCNNFilters = 512\n",
        "        else:\n",
        "            isskipaddingMaxPool = False\n",
        "\n",
        "\n",
        "    x = layers.Flatten(name='Flatten' + str(layerno) ) (x)\n",
        "    print(str(layerno) + ' Flatten  ' )\n",
        "\n",
        "    layerno = layerno + 1\n",
        "\n",
        "    for i in range(noofDenselayers):\n",
        "        x = layers.Dense(noofDensenodes, activation='relu', name='Dense'+ str(layerno) )(x)\n",
        "        print( str(layerno) + ' Dense  ' + str(noofDensenodes) )\n",
        "        layerno = layerno +1\n",
        "        noofDensenodes = round(noofDensenodes/2)\n",
        "\n",
        "    myoutputTensor = layers.Dense(10, activation='softmax', name='DenseMultiClassSoftmaxLayer') (x)\n",
        "\n",
        "    mymodel = Model(myinputTensor, myoutputTensor)\n",
        "\n",
        "    print(mymodel.summary())\n",
        "    \n",
        "    plot_model(mymodel, show_shapes=False, show_layer_names=True, to_file='achildmodel.png')\n",
        "    files.download('achildmodel.png')\n",
        "\n",
        "    \n",
        "\n",
        "  #  plot_model(mymodel, show_shapes=True, to_file='models'+str(ExpNo) + '.png')\n",
        "   # plot_model(mymodel, show_shapes=False, to_file='m'+str(ExpNo) + '.png')\n",
        "\n",
        "\n",
        "    return mymodel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XJX4hB8BgOj9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_callbacks(expno):\n",
        "   # tensorboard_callback = TensorBoard(log_dir=os.path.join(os.getcwd(), \"log\", \"am18d301_Exp1\" + str(expno) ), histogram_freq=1, batch_size=32,   write_graph=False, write_grads=False)\n",
        "   # checkpoint_callback = ModelCheckpoint(filepath=\"./model-weights.{epoch:02d}.hdf5\", monitor='val_acc', verbose=0, save_best_only=True)\n",
        "    earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=1, verbose=1, mode='auto')\n",
        "    return [ earlystop]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DgMRQjrTgRKR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_model_metrics(model, xtest, ytest ):\n",
        "    loss, accuracy = model.evaluate(x=xtest, y=ytest)\n",
        "    print(\"\\n model test loss is \"+str(loss)+\" accuracy is \"+str(accuracy))\n",
        "\n",
        "    y_softmax = model.predict(xtest)  # this is an n x class matrix of probabilities\n",
        "    y_hat = y_softmax.argmax(axis=-1)  # this will be the class number.\n",
        "    test_y = ytest.argmax(axis=-1)  # our test data is also categorical\n",
        "    print(classification_report(test_y, y_hat))\n",
        "    return [loss, accuracy]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-QnaNl67gTnx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_imgs(X):\n",
        "    plt.figure(1)\n",
        "    k = 0\n",
        "    for i in range(0,4):\n",
        "        for j in range(0,4):\n",
        "            plt.subplot2grid((4,4),(i,j))\n",
        "            plt.imshow(toimage(X[k]))\n",
        "            k = k+1\n",
        "    # show the plot\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VtGT5APagV5D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convertprecision(alongfloat):\n",
        "    alongfloat1 = Decimal(alongfloat * 100)\n",
        "    alongfloat2 = round(alongfloat1, 2)\n",
        "    myformatedfloat = float(alongfloat2)\n",
        "    return myformatedfloat "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wE18NNodgj6M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def runaexpeirment(ExpName, anetworkmodel):\n",
        "\n",
        "    mymodel = anetworkmodel\n",
        "\n",
        "    (xtrain1, ytrain1), (xtest, ytest) = datasets.cifar10.load_data()\n",
        "    \n",
        "    plot_imgs(xtrain1[:16])\n",
        "\n",
        "    xtrain  = xtrain1[:42000, :]\n",
        "    ytrain = ytrain1[:42000, :]\n",
        "\n",
        "    xval = xtrain1[42000:, :]\n",
        "    yval = ytrain1[42000:, :]\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "    datagen.fit(xtrain)\n",
        "    \n",
        "\n",
        "    print( 'Shape of CIFAR Training Set Inputs: ' + str(xtrain.shape) )\n",
        "    print( 'Shape of CIFAR Training Set Labels: ' + str(ytrain.shape) )\n",
        "    print( 'Shape of CIFAR Test Set Inputs: ' + str(xtest.shape) )\n",
        "    print( 'Shape of CIFAR Validation Set Inputs: ' + str(xval.shape) )\n",
        "\n",
        "\n",
        "    xtrain = xtrain.astype('float16') * 1/255\n",
        "    xtest = xtest.astype('float16') * 1/255\n",
        "    xval = xval.astype('float16') * 1/255\n",
        "\n",
        "    trainSetSize = len(xtrain)\n",
        "    testSetSize = len(xtest)\n",
        "    valSetSize = len(xval)\n",
        "\n",
        "    xtrain = xtrain.reshape((trainSetSize, 32, 32, 3))\n",
        "    xtest = xtest.reshape((testSetSize, 32, 32, 3))\n",
        "    xval = xval.reshape((valSetSize,32, 32, 3))\n",
        "\n",
        "    ytrain = utils.to_categorical(ytrain)\n",
        "    ytest = utils.to_categorical(ytest)\n",
        "    yval = utils.to_categorical(yval)\n",
        "\n",
        "    print('After preprocessing.. normalize to 1, OHE, reshaping')\n",
        "    print( 'Shape of CIFAR Training Set Inputs: ' + str(xtrain.shape) )\n",
        "    print( 'Shape of CIFAR Training Set Labels: ' + str(ytrain.shape) )\n",
        "    print( 'Shape of CIFAR Test Set Inputs: ' + str(xtest.shape) )\n",
        "\n",
        "\n",
        "    mymodel.compile(optimizer=keras.optimizers.RMSprop(), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "    mycallbacksfunction = create_callbacks(ExpName)\n",
        "\n",
        "   # history = mymodel.fit(xtrain, ytrain, epochs=2, batch_size=128,\n",
        "                         # validation_data=(xval,yval),\n",
        "                         # verbose=1, \n",
        "                         # callbacks=mycallbacksfunction\n",
        "                         # )\n",
        "\n",
        "    mybatchsize = 128\n",
        "    history = mymodel.fit_generator( datagen.flow(xtrain, ytrain, batch_size=mybatchsize),\n",
        "                    steps_per_epoch=xtrain.shape[0] / mybatchsize, \n",
        "                    epochs=1,\n",
        "                    verbose=1,\n",
        "                    validation_data=(xval,yval)\n",
        "                      )\n",
        "\n",
        "    #save to disk\n",
        "    model_json = mymodel.to_json()\n",
        "    with open('model' + str(ExpName) + 's.json', 'w') as json_file:\n",
        "        json_file.write(model_json)\n",
        "    mymodel.save_weights('model'  + str(ExpName) + 's.h5') \n",
        "\n",
        "    myTESTloss, myTESTaccuracy = print_model_metrics( mymodel, xtest, ytest )\n",
        "    myVALloss, myVALaccuracy = print_model_metrics( mymodel, xval, yval )\n",
        "    myTRAINloss, myTRAINaccuracy = print_model_metrics( mymodel, xtrain, ytrain)\n",
        "\n",
        "    myTESTaccuracy = convertprecision(myTESTaccuracy)\n",
        "    myVALaccuracy = convertprecision(myVALaccuracy)\n",
        "    myTRAINaccuracy = convertprecision(myTRAINaccuracy)\n",
        "    \n",
        "\n",
        "    print(' \\n RESULTS')\n",
        "    print('TRAINING accuracy = ' + str(myTRAINaccuracy ))\n",
        "    print('VAL accuracy = ' + str(myVALaccuracy))\n",
        "    print('TEST accuracy = ' + str(myTESTaccuracy))\n",
        "    \n",
        "    \n",
        "\n",
        "    return myTRAINaccuracy, myVALaccuracy, myTESTaccuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rC0hKiLpgq7V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Find insights about a network such as how deep is the network, memorizationcapacity, generalizationcapacity, noofCNNs, kernalsize, amountofnonlinearity\n",
        "def extractNetworkInsights(anetwork):\n",
        "    print('Analzing the Network insights')\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hCnaRjjrgxBK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ExpName = 2000\n",
        "islistcreated = False\n",
        "ListofNetworks = list()\n",
        "nooffiltersstarting =  32\n",
        "networkwidthTamperRate = 2\n",
        "noofDenselayers = 0\n",
        "noofDensenodes = 64 \n",
        "stride = 1\n",
        "maxpool = 2\n",
        "noofPARALLELbranches = 1\n",
        "noofCNNlayers = 6\n",
        "kernalsize = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KrVQaDstg1V5",
        "colab_type": "code",
        "outputId": "558efbc3-09a6-4885-cc53-dd12901a267e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1154
        }
      },
      "cell_type": "code",
      "source": [
        "#def createANetwork(ExpNo, noofCNNlayers, noofDenselayers, noofCNNFilters, noofDensenodes  , noofPARALLELbranches , networkwidthTamperRate):\n",
        "\n",
        "for iterate in range( 0, 1):\n",
        "  \n",
        "    ExpName = ExpName + 1\n",
        "    generatedNetwork =  createANetwork(ExpName, noofCNNlayers,noofDenselayers, nooffiltersstarting, noofDensenodes  ,networkwidthTamperRate, stride, maxpool,  noofPARALLELbranches, kernalsize )\n",
        "    aTRAINaccuracy, aVALaccuracy, aTESTaccuracy = runaexpeirment(ExpName, generatedNetwork )\n",
        "    atuple = tuple((ExpName, aTRAINaccuracy, aVALaccuracy, aTESTaccuracy ,  noofCNNlayers,noofDenselayers,  nooffiltersstarting, noofDensenodes  ,networkwidthTamperRate  , stride, maxpool, noofPARALLELbranches , kernalsize, generatedNetwork))\n",
        "\n",
        "    ListofNetworks.append(atuple)\n",
        "\n",
        "    print(\" ADDED\")\n",
        "    print(atuple)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "329/328 [==============================] - 33s 102ms/step - loss: 1.8936 - acc: 0.3923 - val_loss: 2.1050 - val_acc: 0.3635\n",
            "10000/10000 [==============================] - 2s 210us/step\n",
            "\n",
            " model test loss is 2.1271594276428223 accuracy is 0.3491\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.36      0.44      1000\n",
            "           1       0.70      0.40      0.51      1000\n",
            "           2       0.42      0.03      0.06      1000\n",
            "           3       0.20      0.21      0.21      1000\n",
            "           4       0.50      0.03      0.06      1000\n",
            "           5       0.22      0.52      0.31      1000\n",
            "           6       0.72      0.15      0.25      1000\n",
            "           7       0.35      0.60      0.45      1000\n",
            "           8       0.74      0.39      0.51      1000\n",
            "           9       0.28      0.80      0.42      1000\n",
            "\n",
            "   micro avg       0.35      0.35      0.35     10000\n",
            "   macro avg       0.47      0.35      0.32     10000\n",
            "weighted avg       0.47      0.35      0.32     10000\n",
            "\n",
            "8000/8000 [==============================] - 2s 195us/step\n",
            "\n",
            " model test loss is 2.1049903593063353 accuracy is 0.3635\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.36      0.45       812\n",
            "           1       0.68      0.41      0.51       801\n",
            "           2       0.55      0.04      0.07       762\n",
            "           3       0.25      0.25      0.25       824\n",
            "           4       0.47      0.03      0.06       775\n",
            "           5       0.24      0.53      0.33       850\n",
            "           6       0.77      0.15      0.25       782\n",
            "           7       0.37      0.63      0.46       783\n",
            "           8       0.74      0.42      0.54       798\n",
            "           9       0.28      0.78      0.41       813\n",
            "\n",
            "   micro avg       0.36      0.36      0.36      8000\n",
            "   macro avg       0.49      0.36      0.33      8000\n",
            "weighted avg       0.49      0.36      0.33      8000\n",
            "\n",
            "42000/42000 [==============================] - 8s 197us/step\n",
            "\n",
            " model test loss is 2.084280023574829 accuracy is 0.3615\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.36      0.45      4188\n",
            "           1       0.72      0.41      0.52      4199\n",
            "           2       0.50      0.04      0.07      4238\n",
            "           3       0.24      0.24      0.24      4176\n",
            "           4       0.53      0.04      0.07      4225\n",
            "           5       0.23      0.53      0.32      4150\n",
            "           6       0.74      0.15      0.26      4218\n",
            "           7       0.37      0.62      0.46      4217\n",
            "           8       0.77      0.41      0.54      4202\n",
            "           9       0.28      0.80      0.41      4187\n",
            "\n",
            "   micro avg       0.36      0.36      0.36     42000\n",
            "   macro avg       0.50      0.36      0.33     42000\n",
            "weighted avg       0.50      0.36      0.33     42000\n",
            "\n",
            " \n",
            " RESULTS\n",
            "TRAINING accuracy = 36.15\n",
            "VAL accuracy = 36.35\n",
            "TEST accuracy = 34.91\n",
            " ADDED\n",
            "(2001, 36.15, 36.35, 34.91, 6, 0, 32, 64, 2, 1, 2, 1, 3, <keras.engine.training.Model object at 0x7f2fbbb92198>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U9fCGeVWMHn9",
        "colab_type": "code",
        "colab": {
          "height": 1137
        },
        "outputId": "1fe09504-8a92-4abc-df9f-bd9350563ee7"
      },
      "cell_type": "code",
      "source": [
        "#def createANetwork(ExpNo, noofCNNlayers, noofDenselayers, noofCNNFilters, noofDensenodes  , noofPARALLELbranches , networkwidthTamperRate):\n",
        "\n",
        "for iterate in range( 0, 3):\n",
        "  \n",
        "    ExpName = ExpName + 1\n",
        "    generatedNetwork =  createANetwork(ExpName, noofCNNlayers,noofDenselayers, nooffiltersstarting, noofDensenodes  ,networkwidthTamperRate, stride, maxpool,  noofPARALLELbranches, kernalsize )\n",
        "    aTRAINaccuracy, aVALaccuracy, aTESTaccuracy = runaexpeirment(ExpName, generatedNetwork )\n",
        "    atuple = tuple((ExpName, aTRAINaccuracy, aVALaccuracy, aTESTaccuracy ,  noofCNNlayers,noofDenselayers,  nooffiltersstarting, noofDensenodes  ,networkwidthTamperRate  , stride, maxpool, noofPARALLELbranches , kernalsize, generatedNetwork))\n",
        "\n",
        "    ListofNetworks.append(atuple)\n",
        "\n",
        "    print(\" ADDED\")\n",
        "    print(atuple)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Conv2D  Filters=32.    kernel size=(3 , 3 ) . stride=1     Relu\n",
            "2 Conv2D  Filters=32.    kernel size=(3 , 3 ) . stride=1     Relu\n",
            "3 MaxPool  . Poolsize=2\n",
            "  Dropout 0.2\n",
            "4 Conv2D  Filters=64.    kernel size=(3 , 3 ) . stride=1     Relu\n",
            "5 Conv2D  Filters=64.    kernel size=(3 , 3 ) . stride=1     Relu\n",
            "6 MaxPool  . Poolsize=1\n",
            "  Dropout 0.2\n",
            "7 Conv2D  Filters=128.    kernel size=(3 , 3 ) . stride=1     Relu\n",
            "8 Conv2D  Filters=128.    kernel size=(3 , 3 ) . stride=1     Relu\n",
            "9 MaxPool  . Poolsize=1\n",
            "  Dropout 0.2\n",
            "10 Flatten  \n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "1 (InputLayer)               (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "CNNlayer1 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "CNNlayer2 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "MaxPool3 (MaxPooling2D)      (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "CNNlayer4 (Conv2D)           (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "CNNlayer5 (Conv2D)           (None, 10, 10, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 10, 10, 64)        256       \n",
            "_________________________________________________________________\n",
            "MaxPool6 (MaxPooling2D)      (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "CNNlayer7 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "CNNlayer8 (Conv2D)           (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "MaxPool9 (MaxPooling2D)      (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "Flatten10 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "DenseMultiClassSoftmaxLayer  (None, 10)                46090     \n",
            "=================================================================\n",
            "Total params: 334,890\n",
            "Trainable params: 333,994\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: `toimage` is deprecated!\n",
            "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use Pillow's ``Image.fromarray`` directly instead.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Tz0yrr5ljE0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(xtraincheck, ytraincheck), (xtestcheck, ytestcheck) = datasets.cifar10.load_data()\n",
        "myimageJ = xtraincheck[114]\n",
        "myimageJnormalized = myimageJ.astype('float16') * 1/255"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}